{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"combined_season1-37.tsv.zip\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>value</th>\n",
       "      <th>daily_double</th>\n",
       "      <th>category</th>\n",
       "      <th>comments</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>air_date</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>no</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>-</td>\n",
       "      <td>River mentioned most often in the Bible</td>\n",
       "      <td>the Jordan</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>no</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>-</td>\n",
       "      <td>Scottish word for lake</td>\n",
       "      <td>loch</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>yes</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>-</td>\n",
       "      <td>River in this famous song:</td>\n",
       "      <td>the Volga River</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>no</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>-</td>\n",
       "      <td>American river only 33 miles shorter than the ...</td>\n",
       "      <td>the Missouri</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>no</td>\n",
       "      <td>LAKES &amp; RIVERS</td>\n",
       "      <td>-</td>\n",
       "      <td>World's largest lake, nearly 5 times as big as...</td>\n",
       "      <td>the Caspian Sea</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389440</th>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>no</td>\n",
       "      <td>FOUNDRY</td>\n",
       "      <td>-</td>\n",
       "      <td>This hefty noisemaker from Whitechapel Foundry...</td>\n",
       "      <td>Big Ben</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389441</th>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>no</td>\n",
       "      <td>FOUNDRY</td>\n",
       "      <td>-</td>\n",
       "      <td>Around 4,000 years ago, the first foundries in...</td>\n",
       "      <td>bronze</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389442</th>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>no</td>\n",
       "      <td>FOUNDRY</td>\n",
       "      <td>-</td>\n",
       "      <td>Several different foundries worked for 4 month...</td>\n",
       "      <td>Monitor</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389443</th>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>no</td>\n",
       "      <td>FOUNDRY</td>\n",
       "      <td>-</td>\n",
       "      <td>Once one of the largest of its kind, the Gary ...</td>\n",
       "      <td>U.S. Steel</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389444</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>19th CENTURY AMERICAN WOMEN</td>\n",
       "      <td>-</td>\n",
       "      <td>2 of the 3 women depicted on the first statue ...</td>\n",
       "      <td>(2 of) (Sojourner) Truth, (Susan B.) Anthony, ...</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389445 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        round  value daily_double                     category comments  \\\n",
       "0           1    100           no               LAKES & RIVERS        -   \n",
       "1           1    200           no               LAKES & RIVERS        -   \n",
       "2           1    800          yes               LAKES & RIVERS        -   \n",
       "3           1    400           no               LAKES & RIVERS        -   \n",
       "4           1    500           no               LAKES & RIVERS        -   \n",
       "...       ...    ...          ...                          ...      ...   \n",
       "389440      2    400           no                      FOUNDRY        -   \n",
       "389441      2    800           no                      FOUNDRY        -   \n",
       "389442      2   1200           no                      FOUNDRY        -   \n",
       "389443      2   1600           no                      FOUNDRY        -   \n",
       "389444      3      0           no  19th CENTURY AMERICAN WOMEN        -   \n",
       "\n",
       "                                                   answer  \\\n",
       "0                 River mentioned most often in the Bible   \n",
       "1                                  Scottish word for lake   \n",
       "2                              River in this famous song:   \n",
       "3       American river only 33 miles shorter than the ...   \n",
       "4       World's largest lake, nearly 5 times as big as...   \n",
       "...                                                   ...   \n",
       "389440  This hefty noisemaker from Whitechapel Foundry...   \n",
       "389441  Around 4,000 years ago, the first foundries in...   \n",
       "389442  Several different foundries worked for 4 month...   \n",
       "389443  Once one of the largest of its kind, the Gary ...   \n",
       "389444  2 of the 3 women depicted on the first statue ...   \n",
       "\n",
       "                                                 question    air_date notes  \n",
       "0                                              the Jordan  1984-09-10     -  \n",
       "1                                                    loch  1984-09-10     -  \n",
       "2                                         the Volga River  1984-09-10     -  \n",
       "3                                            the Missouri  1984-09-10     -  \n",
       "4                                         the Caspian Sea  1984-09-10     -  \n",
       "...                                                   ...         ...   ...  \n",
       "389440                                            Big Ben  2021-08-13     -  \n",
       "389441                                             bronze  2021-08-13     -  \n",
       "389442                                            Monitor  2021-08-13     -  \n",
       "389443                                         U.S. Steel  2021-08-13     -  \n",
       "389444  (2 of) (Sojourner) Truth, (Susan B.) Anthony, ...  2021-08-13     -  \n",
       "\n",
       "[389445 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['air_date'] = pd.to_datetime(df['air_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On 11/26/2001, the values for the questions doubled for both rounds of Jeopardy. Need to adjust the earlier episodes to have the same values as post-11/26/2001 shows.\n",
    "df.loc[df['air_date'] < '2001-11-26', \"value\"] = df.value * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Daily Doubles since the contestants can wager any amounts for those\n",
    "df = df[df[\"daily_double\"] != 'yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only standard values (this will remove Final Jeopardy questions, which do not have a set amount and set are at '0', as well as the handful of non-standard values that are likely typos)\n",
    "df = df.loc[df['value'].isin([200, 400, 600, 800, 1000, 400, 800, 1200, 1600, 2000])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import string to remove punctuation\n",
    "\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_punctuation(text):\n",
    "    nopunct=[words for words in text if words not in string.punctuation]\n",
    "    words_without_punct=''.join(nopunct)\n",
    "    return words_without_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation and lowercase words in 'category,' 'answer,' and 'question'\n",
    "\n",
    "df['category'] = df['category'].apply(lambda x: no_punctuation(x).lower())\n",
    "df['answer'] = df['answer'].apply(lambda x: no_punctuation(x).lower())\n",
    "df['question'] = df['question'].apply(lambda x: no_punctuation(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove numerals from 'category,' 'answer,' and 'question'\n",
    "\n",
    "df['category'] = df['category'].str.replace('\\d+', '')\n",
    "df['answer'] = df['answer'].str.replace('\\d+', '')\n",
    "df['question'] = df['question'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "      <th>value</th>\n",
       "      <th>daily_double</th>\n",
       "      <th>category</th>\n",
       "      <th>comments</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>air_date</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>no</td>\n",
       "      <td>lakes  rivers</td>\n",
       "      <td>-</td>\n",
       "      <td>river mentioned most often in the bible</td>\n",
       "      <td>the jordan</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>no</td>\n",
       "      <td>lakes  rivers</td>\n",
       "      <td>-</td>\n",
       "      <td>scottish word for lake</td>\n",
       "      <td>loch</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>no</td>\n",
       "      <td>lakes  rivers</td>\n",
       "      <td>-</td>\n",
       "      <td>american river only  miles shorter than the mi...</td>\n",
       "      <td>the missouri</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>no</td>\n",
       "      <td>lakes  rivers</td>\n",
       "      <td>-</td>\n",
       "      <td>worlds largest lake nearly  times as big as su...</td>\n",
       "      <td>the caspian sea</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>no</td>\n",
       "      <td>inventions</td>\n",
       "      <td>-</td>\n",
       "      <td>marconis wonderful wireless</td>\n",
       "      <td>the radio</td>\n",
       "      <td>1984-09-10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389438</th>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>no</td>\n",
       "      <td>lost</td>\n",
       "      <td>-</td>\n",
       "      <td>in a moveable feast gertrude stein is quoted a...</td>\n",
       "      <td>lost generation</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389440</th>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>no</td>\n",
       "      <td>foundry</td>\n",
       "      <td>-</td>\n",
       "      <td>this hefty noisemaker from whitechapel foundry...</td>\n",
       "      <td>big ben</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389441</th>\n",
       "      <td>2</td>\n",
       "      <td>800</td>\n",
       "      <td>no</td>\n",
       "      <td>foundry</td>\n",
       "      <td>-</td>\n",
       "      <td>around  years ago the first foundries in mesop...</td>\n",
       "      <td>bronze</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389442</th>\n",
       "      <td>2</td>\n",
       "      <td>1200</td>\n",
       "      <td>no</td>\n",
       "      <td>foundry</td>\n",
       "      <td>-</td>\n",
       "      <td>several different foundries worked for  months...</td>\n",
       "      <td>monitor</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389443</th>\n",
       "      <td>2</td>\n",
       "      <td>1600</td>\n",
       "      <td>no</td>\n",
       "      <td>foundry</td>\n",
       "      <td>-</td>\n",
       "      <td>once one of the largest of its kind the gary w...</td>\n",
       "      <td>us steel</td>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363765 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        round  value daily_double       category comments  \\\n",
       "0           1    200           no  lakes  rivers        -   \n",
       "1           1    400           no  lakes  rivers        -   \n",
       "3           1    800           no  lakes  rivers        -   \n",
       "4           1   1000           no  lakes  rivers        -   \n",
       "5           1    200           no     inventions        -   \n",
       "...       ...    ...          ...            ...      ...   \n",
       "389438      2   1600           no           lost        -   \n",
       "389440      2    400           no        foundry        -   \n",
       "389441      2    800           no        foundry        -   \n",
       "389442      2   1200           no        foundry        -   \n",
       "389443      2   1600           no        foundry        -   \n",
       "\n",
       "                                                   answer         question  \\\n",
       "0                 river mentioned most often in the bible       the jordan   \n",
       "1                                  scottish word for lake             loch   \n",
       "3       american river only  miles shorter than the mi...     the missouri   \n",
       "4       worlds largest lake nearly  times as big as su...  the caspian sea   \n",
       "5                             marconis wonderful wireless        the radio   \n",
       "...                                                   ...              ...   \n",
       "389438  in a moveable feast gertrude stein is quoted a...  lost generation   \n",
       "389440  this hefty noisemaker from whitechapel foundry...          big ben   \n",
       "389441  around  years ago the first foundries in mesop...           bronze   \n",
       "389442  several different foundries worked for  months...          monitor   \n",
       "389443  once one of the largest of its kind the gary w...         us steel   \n",
       "\n",
       "         air_date notes  \n",
       "0      1984-09-10     -  \n",
       "1      1984-09-10     -  \n",
       "3      1984-09-10     -  \n",
       "4      1984-09-10     -  \n",
       "5      1984-09-10     -  \n",
       "...           ...   ...  \n",
       "389438 2021-08-13     -  \n",
       "389440 2021-08-13     -  \n",
       "389441 2021-08-13     -  \n",
       "389442 2021-08-13     -  \n",
       "389443 2021-08-13     -  \n",
       "\n",
       "[363765 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 'answer' (Jeopardy questions) as the feature and 'value' as the target\n",
    "\n",
    "X = df['answer']\n",
    "y = df['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the vector with stop words, max_features=1000, and bigrams\n",
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range= (1, 2), max_features=1000)\n",
    "\n",
    "# Fit the vectorizer on X_train and transform it\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_vectorized: (272823, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_vectorized:\", X_train_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-532.22380864, -532.59566592])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic random forest\n",
    "random_forest = RandomForestRegressor(max_depth=2)\n",
    "random_forest_cv = cross_val_score(random_forest, X_train_vectorized, y_train, scoring='neg_root_mean_squared_error', cv=2)\n",
    "random_forest_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Random Forest: 532.4167569768802\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic Random Forest:\", -(random_forest_cv.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [5, 10, 15]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor()\n",
    "\n",
    "rf_grid_param1 = {'max_depth': [5, 10, 15]}\n",
    "\n",
    "rf_grid1 = GridSearchCV(random_forest_model, rf_grid_param1, cv=2)\n",
    "\n",
    "rf_grid1.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestRegressor(max_depth=15),\n",
       "             param_grid={'min_samples_split': [2, 4, 6]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15)\n",
    "\n",
    "rf_grid_param2 = {'min_samples_split': [2, 4, 6]}\n",
    "\n",
    "rf_grid2 = GridSearchCV(random_forest_model, rf_grid_param2, cv=2)\n",
    "\n",
    "rf_grid2.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestRegressor(max_depth=15, min_samples_split=4),\n",
       "             param_grid={'min_samples_leaf': [1, 2, 4]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15, min_samples_split=4)\n",
    "\n",
    "rf_grid_param3 = {'min_samples_leaf': [1,2,4]}\n",
    "\n",
    "rf_grid3 = GridSearchCV(random_forest_model, rf_grid_param3, cv=2)\n",
    "\n",
    "rf_grid3.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestRegressor(max_depth=15, min_samples_split=4),\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15, min_samples_split=4, min_samples_leaf=1)\n",
    "\n",
    "rf_grid_param4 = {'max_features': [\"auto\", \"sqrt\", \"log2\"]}\n",
    "\n",
    "rf_grid4 = GridSearchCV(random_forest_model, rf_grid_param4, cv=2)\n",
    "\n",
    "rf_grid4.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'auto'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestRegressor(max_depth=15, min_samples_split=4),\n",
       "             param_grid={'bootstrap': [True, False]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15, min_samples_split=4, min_samples_leaf=1, max_features='auto')\n",
    "\n",
    "rf_grid_param5 = {'bootstrap': [True, False]}\n",
    "\n",
    "rf_grid5 = GridSearchCV(random_forest_model, rf_grid_param5, cv=2)\n",
    "\n",
    "rf_grid5.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestRegressor(max_depth=15, min_samples_split=4),\n",
       "             param_grid={'n_estimators': [5, 20, 50, 100]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15, min_samples_split=4, min_samples_leaf=1, max_features='auto', bootstrap=True)\n",
    "\n",
    "rf_grid_param6 = {'n_estimators': [5,20,50,100]}\n",
    "\n",
    "rf_grid6 = GridSearchCV(random_forest_model, rf_grid_param6, cv=2)\n",
    "\n",
    "rf_grid6.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=RandomForestRegressor(max_depth=15, min_samples_split=4),\n",
       "             param_grid={'n_estimators': [100, 115, 130]})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use Grid Search to find best parameters for random forest\n",
    "random_forest_model = RandomForestRegressor(max_depth=15, min_samples_split=4, min_samples_leaf=1, max_features='auto', bootstrap=True)\n",
    "\n",
    "rf_grid_param7 = {'n_estimators': [100, 115, 130]}\n",
    "\n",
    "rf_grid7 = GridSearchCV(random_forest_model, rf_grid_param7, cv=2)\n",
    "\n",
    "rf_grid7.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid7.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the tuned random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuned random forest\n",
    "tuned_forest = RandomForestRegressor(max_depth=15, n_estimators=100, min_samples_split=4, min_samples_leaf=1, max_features='auto', bootstrap=True)\n",
    "tuned_forest_cv = cross_val_score(tuned_forest, X_train_vectorized, y_train, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-530.49842151, -531.79691278, -528.39640175, -532.35609186,\n",
       "       -531.01993146])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_forest_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Random Forest: 532.4097372781623\n",
      "Tuned Random Forest: 530.8135518739608\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic Random Forest:\", -(random_forest_cv.mean()))\n",
    "print(\"Tuned Random Forest:\", -(tuned_forest_cv.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run test data with tuned random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training sets\n",
    "tuned_forest.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize X_test\n",
    "X_test_vectorized = tfidf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = tuned_forest.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_best_random_forest = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532.8174097114581"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_best_random_forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
